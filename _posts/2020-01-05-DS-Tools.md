---
title: "Notes on Data Science Tools"
date: 2019-01-01
tags: [reviews, DS Tools]
excerpt: "reviews, DS Tools"
mathjax: "true"
---
## Good websites/blogs/resources

[ClaoudML](https://www.claoudml.com/)

[SuperDataScience](https://www.superdatascience.com/)

## Datasets

[Kaggle datasets](https://www.kaggle.com/datasets)

[UCI dataset repo](https://archive.ics.uci.edu/ml/datasets.php)

[Google dataset search](https://datasetsearch.research.google.com/)

[NLP dataset@Github](https://github.com/niderhoff/nlp-datasets)

[NLP dataset@ML Mastery](https://machinelearningmastery.com/datasets-natural-language-processing/)

## Career Advices

[Medium: 12 things I wish I’d known before starting as a Data Scientist](https://medium.com/deliberate-data-science/12-things-i-wish-id-known-before-starting-as-a-data-scientist-45989be6300e)

[Medium: The academic trap and data science](The academic trap and data science)

[Medium: Hiring data scientists](https://medium.com/@skyetetra/hiring-data-scientists-part-1-2813ba44be9b)

[Forbes: Radical Change Is Coming To Data Science Jobs](https://www.forbes.com/sites/forbestechcouncil/2019/03/01/radical-change-is-coming-to-data-science-jobs/#44bda5fbdfcc)

Main point: Many of the data science tasks today will become automated and part of the anaytics platform. The five typical career path for future data scientists are: 1. Generalist; 2. Industry specialists; 3. Deep specialists; 4. Analytics developers; 5. Data engineers

[CrowdFLower: Data Science Report 2017](https://visit.figure-eight.com/rs/416-ZBE-142/images/CrowdFlower_DataScienceReport.pdf)

Main point: most of the time is spent with cleaning and organizing the data

## Python Programming

### Data Types
  
  * Strings: 'python', "python"
  
  * Numbers: 10, 10.5 10+5j
  
  * Lists: ['python', 'website']
  
  * Tuples: ('python', 'website')
  
  * Dictionary: {'name':'python', 'number':1}
  
  * Sets: {1,2,3}
  
  * Boolean: 0, 1, True, False

### Function

### Class

### Data structure

### Array Basic Sorting

### LinkedList 

### Recursion 

### Heap

### Queue and Stack

### Binary Search

### Binary Tree

### Advanced Tree 

1. complete tree

2. segment tree

3. trie tree

### DFS/BFS

### HashTable

## SQL

### Functions

* Join

* Subquery

* Windows

[Search Text with Regular Expressions](https://dev.mysql.com/doc/refman/8.0/en/regexp.html)

[MySQL: Regular Expressions](https://dev.mysql.com/doc/refman/8.0/en/regexp.html)
### NoSQL databases

1. Elastic Search

2. MongoDB

3. CouchDB 

4. Cassandra

5. HBase

### Questions

* What are the two types of SQL?

* What’s a relational database?

* What’s a table?

* What the difference between structured data and unstructured data?

* How do you create a table?

## ML packages

[scikit-learn](https://scikit-learn.org/stable/)

Auto-sklearn: automatically searches for the right learning algorithm for a new machine learning dataset and optimizes its hyperparameters
[Website](https://www.ml4aad.org/automl/auto-sklearn/)  [Github folder](https://github.com/automl/auto-sklearn)

## Parallel Computing/HPC/Cloud Computing

### Speed up Python

* [Intel Distribution for Python](https://lnkd.in/gk6EB2P)

Optimizes Python for Intel architectures using low-level, high-performance libraries like MKL. Can provide massive speedup for linear algebra routines and ML algorithms.

*[Numba](https://numba.pydata.org/)

Just-in-time compiler (using LLVM) for Python. Replaces slow Python code with optimized machine code at runtime. Super easy to use.

*[swiftapply](https://lnkd.in/gFK285E)

Automatically vectorizes apply calls, or replaces them with the best alternative.

*[Dask](https://lnkd.in/ggiKPvk)

Provides parallelism for analytics by extending arrays, dataframes, and lists to "parallel" versions that are ready for distributed environments, plus provides a dynamic task scheduler.

*[Cython](http://cython.org/)

Compile Python into C extensions. General use tool that can have more flexibility and power than simpler alternatives, at the cost of difficulty.

*[PySpark](https://lnkd.in/gRjExzR)

Runs Python code on distributed Spark clusters. Great for processing big data sets.

[Kyle McKiou Blog](https://www.linkedin.com/posts/kylemckiou_python-activity-6615240757093765120-CrDw)

## Agile Development

## Visualization

[Visual Vocabulary](https://gramener.github.io/visual-vocabulary-vega/)

### [Seaborn](https://seaborn.pydata.org/)

### GGplot

### D3.js

## Matplotlib

### Tableau

### QlikView

## Git

## Excel

[Pivot Tables](https://exceljet.net/excel-pivot-tables)


## Big Data Tools

[5 Full Stack Data Science Technologies for 2020](https://www.business-science.io/business/2019/12/09/data-science-technologies.html)

AWS

Hadoop

MongoDB 

Neo4j 

Spark

1. Spark ML

2. Spark RDD

Flink Streaming

Hive

BigQuery

Hbase

Cassandra

## Business Intelligence Software

PowerBI

KNIME 

Alteryx

Qlik

OBIEE

Web analytics tools (GoogleAnalytics, Adobe, etc.)

## Web scraping

Beautiful Soup

URLLIB

Scrapy

## Latex

[Mathematics in R Markdown](https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html)

## Markdown

[Basic Syntax](https://www.markdownguide.org/basic-syntax)

[Math](https://goessner.github.io/markdown-it-texmath/index.html)

<details>
<summary> 
  
</summary>
<br>
  
<br>
</details>
