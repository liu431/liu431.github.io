---
title: "Notes on Machine Learning"
date: 2019-01-01
tags: [reviews, machine learning]
excerpt: "reviews, machine learning"
mathjax: "true"
---

## Concepts

### Statistical Learning vs Machine Learning

 Different goals: 
 
 Statistical Learning: inference and generalization
 
 Machine Learning: maxmize prediction 
 
 > Machine learning is the science of getting computers to act without being explicitly programmed. - Andrew Ng
 
 > Field of study that gives computers the ability to learn without being explicitly programmed. -Arthur Samuel, IBM, 1959
 
### Model

  Common form: $$y = f(x) + \epsilon $$; Interested in estimating functional form of f(x)
  
  Approaches: parametric; non=parametric estimation
 
### Selecting and fitting a model

### Flexible models vs. inflexible models 
 
  `Flexibility` is a measure of how much a fitted model can vary with a given data.
  
  * Example of flexible models (high variance, low bias): splines, 10 degree curve, Support Vector Machines
  
  * Example of inflexible models (low variance, high bias): linear regression

 * When a inflexible model is preferred:
 
   1. interpretablility: understand how the explanatory variables affect the response variable
      
   2. a small e size (small n) and large number of predictors (large p)
   
   3. the variance of the error terms, i.e. $$sigma^{2}=Var(\epsilon)$$, is extremely high
 
 * When a flexible model is preferred:
   
   1. a large sample size (large n) and small number of predictors (small p)
   
   2. relationship between the predictors and response is highly non-linear
   
A flexible model will cause you to fit too much of the noise in the problem (when variance of the error terms is high).

[Quora answer](https://www.quora.com/What-are-flexible-statistical-learning-methods)

### Error

Error = Irreducible Error + $$Bias^2$$ + Variance

### Error/ Bias / Variance

#### Bias

Error caused by choosing an algorithm that cannot accurately model the signal in the data, i.e. the model is too general or was incorrectly selected. For example, selecting a simple linear regression to model highly non-linear data would result in error due to bias.

#### Variance

error from an estimator being too specific and learning relationships that are specific to the training set but do not generalize to new samples well. Variance can come from fitting too closely to noise in the data, and models with high variance are extremely sensitive to changing inputs. Example: Creating a decision tree that splits the training set until every leaf node only contains 1 sample.

#### Irreducible error 

error caused by noise in the data that cannot be removed through modeling. Example: inaccuracy in data collection causes irreducible error.

[Kyle McKiou Blog](https://www.linkedin.com/posts/kylemckiou_datascience-dsdj-qanda-activity-6619603364747575296-w0Ka)

#### Bias-variance tradeoff

trade-off between underfitting and overfitting

From simple to complex models, flexibility increases, variance increases, bias decreases.

As you decrease variance, you tend to increase bias. As you decrease bias, you tend to increase variance.

<img src="/images/ML/Biasvariance.png" class="img-responsive" alt=""> 

Metrics for evaluating models

"No Free Lunch Theorem"

### TPR/FPR/TNR/FNR

Optimization Methods

1. Netwon's method

2. Quasi-Newton methods (ex. LBFGS)

3. Gradient Descent

### Overfitting

When a model makes much better predictions on known data (data included in the training set) than unknown data (data not included in the training set); High variance, low bias; Flexible model

Combate overfitting:

* simplify the model by use fewer parameters
* simply the model by changing the hyperparameters
* simplify the model by introducing regularization
* select a different model
* use more training data
* gather better quality data

[Kyle McKiou Blog](https://www.linkedin.com/posts/kylemckiou_datascience-dsdj-machinelearning-activity-6613065673839120386-vAYB)


Hyper-parameter tuning 

### Resampling Methods

* Essential to test and evaluate statistical models

* Repeatedly draw from your original sample to obtain additional information about the model

### Encoding categorical data

* Label encoding (non-ordinal) - each category is assigned a numeric value not representing any ordering. Example: [red, blue, green] could be encoded to [8, 5, 11].

* Label encoding (ordinal) - each category is assigned a numeric value representing an ordering. Example: [small, medium, large] could be encoded to [1, 2, 3]

* One-hot encoding - each category is transformed into a new binary feature, with all records being marked 1/True or 0/False. Example: color = [red, blue, green] could be encoded to color_red = [1, 0, 0], color_blue = [0, 1, 0], color_green = [0, 0, 1]

[Kyle McKiou Blog](https://www.linkedin.com/posts/kylemckiou_describe-basic-feature-encoding-for-categorical-activity-6621763235186118656-PKU7)

### Train and testing set

* training set is used for model construction (can be reused many times to build different models)

* test set is used to evaluate the performance of the final model (can be used only once)

### Validation

* Intuition: fit the model and evaluate it many times on the same data

* Method: split half of the training data as validation set

* Drawback: validation estimates of the test error rates can be highly variable depending on which observations are sampled into the training and validation sets (ex. outliers in the validation sets)

### Cross-validation

_for evaluating a model’s performance relative to other models_

1. LOOCV: leave-one-out cross validation

only remove one observation for the validation set, and keep all remaining observations in the training set

$$ CV_N = {\frac{1}{N}}{\sum_{i=1}^{N}}MSE_i $$

* Pro: unbiased compared to naive 1-stage validation approach

* Pro: highly flexible and works with any kind of predictive modeling

* Cro: high variance because the N "training sets" are so similar to one another; 

* Cro: computationally expensive

2. K-fold cross-validation: divides the observations into K folds of approximately equal size

Typical K= 5 or 10; Random sampling without replacement

$$ CV_K = \frac{1}{K}\sum_{i=1}^{K}MSE_i $$

* Pro: less variance in test error estimate compared with LOOCV

* Cro: leads to a slight increase in usually bias

3. Other validations

* Stratified cross-validation

* Repeated cross-validation 

* Cross-validation with time series data

### Bootstrapping

_non-parametric measure of the accuracy of a parameter estimate or method_

Purpose: quantify uncertainty associated with some estimator

Loss

1. MSE/Sum of squared errors

2. Cross-entropy

3. Kullback-Leibler (KL) divergence

4. Gini impurity for decision tree

5. Information gain

### Estimators of errors

Mallows’s Cp

[Wiki](https://en.wikipedia.org/wiki/Mallows%27s_Cp)

AIC

BIC

### Data Preparation

1. Cleaning/Pre-processing

2. Missing data

3. Unbalanced data

[How to fix an Unbalanced Dataset@KDnuggets](https://www.kdnuggets.com/2019/05/fix-unbalanced-dataset.html)

4. Feature engineering

5. Feature selection

6. Effective sample size

7. Time correaltions

* backward

* forward

* subset

* L1

* L2

* PCA

### Ensemble learning

1. Bagging

2. Boosting 

3. Xgboost

* xgboost vs DT

* xgboost vs RF

* xgboost vs boosting

Estimation Methods

1. MLE / MAP

2. Expectation-Maxmization algorithm

Occam's Razor
  
  "the simplest solution is most likely the right one"
  
  "when presented with competing hypotheses that make the same predictions, one should select the solution with the fewest assumptions"
  
[Wikipedia](https://en.wikipedia.org/wiki/Occam%27s_razor)

### Building ML Model

<img src="/images/ML/ML.jfif" class="img-responsive" alt=""> 

### Model parameter v.s. Learning hyperparameter

* Model parameters are the rules that mathematically describe the final model that makes predictions, such as slopes or intercept in a linear regression model.

* Learning hyperparameter describes the way in which a model parameter is learned and settings for training the model, e.g. learning rate, penalty terms, number of features to include in a weak predictor, etc.

## Supervised Machine Learning

### Regression

<details>
<summary>Linear Model</summary>
<br>
  
Two assumptions: 1. Linear; 2. Additive (unit changes)
  
<br>

</details>

OLS (ordinary least squares)

Linear model selection

1. Linearity

2. Correlation vs Causality

3. Multicollinearity

4. Interaction variables (ex. x1*x2)

5. Normality

6. Homoscedasticity

7. Monotonic relationship

### Regularization 

1. Ridge

2. Lasso 

3. Elastic-net

Bayesian linear regression

Local regression

Generalized additive model

Logistic regression

### Classification

#### [Key terms](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)

<img src="/images/ML/ClassificationTerms.png" class="img-responsive" alt=""> 

Purpose: categorize all the variables that form the output

Softmax classifier

K-nearest neighbors

Naïve bayes

Support vector machine

#### Evaluation metrics for classification

* Accuracy 

measures the percentage of the time you correctly classify samples: (true positive + true negative) / all samples

* Precision 

measures the percentage of the predicted members that were correctly classified: true positives / (true positives + false positives)

* Recall

measures the percentage of true members that were correctly classified by the algorithm: true positives / (true positives + false negative)

* F1

measurement that balances accuracy and precision (or you can think of it as balancing Type I and Type II error)

* AUC

describes the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one

[Blog](https://arogozhnikov.github.io/2015/10/05/roc-curve.html)

* Gini

a scale and centered version of AUC

* Log-loss

similar to accuracy but increases the penalty for incorrect classifications that are "further" away from their true class. For log-loss, lower values are better.

Source: [Kyle McKiou Blog](https://www.linkedin.com/posts/kylemckiou_datascience-dsdj-qanda-activity-6622850903802290179-jJeS)
  

### Regression vs Classification

 Different `y`: 
 
Regression: response is quantitative (continuous)
 
Classification: response is qualitative (binary/multinomial)

### Tree-based Methods

Classification trees

Boosted regression trees

Random forests

GBDT: Gradient Boosting Decision Tree

[Quora: RF vs GTB](https://www.quora.com/What-are-the-differences-between-Random-Forest-and-Gradient-Tree-Boosting-algorithms)

GBDT loss fucntion

## Unsupervised Machine Learning

### Exploratoty data analysis

### Visualization 

1. Histograms

2. Boxplot

3. t-SNE

### Factor analysis

### Discriminant analysis

### Clustering

1. Distance

2. Clusterability

3. Kmeans

4. Hard partitioning

5. Soft partitioning

6. Hierarchical clustering

7. Gaussian mixture models

### Association rule mining

## Dimensionality reduction

### Principal component analysis

* uses an eigen decomposition to transform the original data into linearly independent eigenvectors

* most important vectors (with highest eigenvalues) are then selected to represent the features in the transformed space

### Non-negative matrix factorization (NMF)

* can be used to reduce dimensionality for certain problem types while preserving more information than PCA

### Embedding techniques 

* various embedding techniques, e.g. finding local neighbors as done in Local Linear Embedding, can be used to reduce dimensionality

### Clustering or centroid techniques 

* each value can be described as a member of a cluster, a linear combination of clusters, or a linear combination of cluster centroids

Source: [Kyle McKiou](https://www.linkedin.com/posts/kylemckiou_datascience-qanda-activity-6624299953705627648-WNjl/)

## Natural Language Processing

### Text Mining

Text mining is the process of examining large collections of text and converting the unstructured text data into structured data for further analysis like visualization and model building.

### Word Embedding

### BERT

### Pre-processing

### Sentiment Analysis

### Topic Models

1. LDA/Gibbs 

2. Structural

3. Non-negative factorization

  1. [tf-idf](https://lnkd.in/ghfqfm7)
  
  2. [N-grams](https://lnkd.in/gCDChaT)
  
  3. [Stemming](https://lnkd.in/gwHuE68)
    
  4. [Lemmatisation](https://lnkd.in/gRU8Q5m)
  
  5. [Cosine similarity](https://lnkd.in/gEMj9hp)
    
  6. [Bag-of-words](https://lnkd.in/gzv7NDX)
  
  7. [Word2vec](https://lnkd.in/gV2yEsn)
  
  8. [LDA](https://lnkd.in/gF2qcnJ)
  
  9. [Edit distance](https://lnkd.in/gy3wU5H)
  
  10. [LSTM](https://lnkd.in/gu9H9vM)

Hidden Markov Chain

### Knowledge graph

Graph theory + Network Science + NLP ---> Better search result with multiple sources

Python tutorial: [how-to-build-knowledge-graph-text-using-spacy](https://www.analyticsvidhya.com/blog/2019/10/how-to-build-knowledge-graph-text-using-spacy/)

Companies: 

[HopHR Knowledge Graph Data Scientist](https://www.linkedin.com/jobs/view/principal-knowledge-graph-data-scientist-md-maryland-at-hophr-1551159673/)

[Big CLoud Data Scientist](https://www.linkedin.com/jobs/view/data-scientist-knowledge-graphs-at-big-cloud-1582125196/?originalSubdomain=sg)

Papers:

[A Review of Relational Machine Learning for Knowledge Graphs](https://arxiv.org/pdf/1503.00759.pdf)

### Application: Chatbox

### Ex: Return ngrams

Q: write a function to return ngram(string,n)  eg: ngram("abc",2) ---> ["a","b","c","ab","bc"]

## Reinforcement Learning

Purpose: max the performance of the machine in a way that helps it to grow

GAN

## Deep Learning

Single layer and multi-layer perceptron neural nets

Convolutional Neural Network

Recursive Neural Network

Self-organizing maps

Dropout

Batch Normalization

Back propagation

Keras

Tensorflow

## Recommendation Systems

Collaborative Filtering

## Information Retrieval

Search/Display

Ads retrieval and recommendation

Spam-traffic and click-farm detection

Infrastructure development

Traffic and revenue prediction

Ads pricing

Audience expansion

## Links to online resources

[An Introduction to Statistical Learning](https://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)

[The Elements of Statistical Learning (2nd edition)](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf)

[CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/)


<details>
<summary> 
  
</summary>
<br>
  
<br>
</details>
