---
title: "Studying Notes on Machine Learning"
date: 2019-01-01
tags: [reviews, machine learning]
excerpt: "reviews, machine learning"
mathjax: "true"
---

## Concepts


<details>
<summary>Statistical Learning vs Machine Learning</summary>
<br>
 
 Different goals: 
 
 Statistical Learning: inference and generalization
 
 Machine Learning: maxmize prediction accuracy
 
 > Machine learning is the science of getting computers to act without being explicitly programmed. - Andrew Ng
 
<br>

</details>


<details>
<summary>Model</summary>
<br>
  
  Common form: y = f(x) + t; Interested in estimating functional form of f(x)
  
  Approaches: parametric; non=parametric estimation
 
<br>

</details>

Selecting and fitting a model

Bias / Variance

Bias-variance tradeoff

Measurement (Precision / Recall / AUC / Accuracy)


<details>
<summary>AUC</summary>
<br>
  
[Blog](https://arogozhnikov.github.io/2015/10/05/roc-curve.html)

<br>

</details>

TPR/FPR/TNR/FNR

Optimization Methods

1. Netwon's method

2. Quasi-Newton methods (ex. LBFGS)

3. Gradient Descent

Underfitting & overfitting

Hyper-parameter tuning 

Resampling Methods

1. Cross-validation

2. Bootstrapping

Loss

1. MSE/Sum of squared errors

2. Cross-entropy

3. Kullback-Leibler (KL) divergence

4. Gini impurity for decision tree

5. Information gain


Data Preparation

1. Cleaning/Pre-processing

2. Missing data

3. Unbalanced data

4. Feature engineering

5. Feature selection

6. Effective sample size

7. Time correaltions

* backward

* forward

* subset

* L1

* L2

* PCA

Ensemble learning

1. Bagging

2. Boosting (xgboost)

Estimation Methods

1. MLE / MAP

2. Expectation-Maxmization algorithm

<details>
<summary>Occam's Razor</summary>
<br>
  
  "the simplest solution is most likely the right one"
  
  "when presented with competing hypotheses that make the same predictions, one should select the solution with the fewest assumptions"
  
[Wikipedia](https://en.wikipedia.org/wiki/Occam%27s_razor)

<br>

</details>

## Supervised Machine Learning

<details>
<summary>Linear Model</summary>
<br>
  
Two assumptions: 1. Linear; 2. Additive (unit changes)
  
<br>

</details>

OLS (ordinary least squares)

Linear model selection

1. Linearity

2. Correlation vs Causality

3. Multicollinearity

4. Interaction variables (ex. x1*x2)

5. Normality

6. Homoscedasticity

7. Monotonic relationship

Regularization 

1. Ridge

2. Lasso 

3. Elastic-net

Bayesian linear regression

Local regression

<details>
<summary>Regression vs Classification</summary>
<br>
 
 Different y: 
 
Regression: response is quantitative (continuous)
 
Classification: response is qualitative (binary/multinomial)

<br>

</details>

Generalized additive model

Logistic regression

Softmax classifier

K-nearest neighbors

Na√Øve bayes

Support vector machine

Classification trees

Boosted regression trees

Random forests

## Unsupervised Machine Learning

Exploratoty data analysis

Visualization 

1. Histograms

2. Boxplot

3. t-SNE

Factor analysis

Principal component analysis

Discriminant analysis

Clustering

1. Distance

2. Clusterability

3. Kmeans

4. Hard partitioning

5. Soft partitioning

6. Hierarchical clustering

7. Gaussian mixture models

Association rule mining


## Natural Language Processing

Text Mining

Text mining is the process of examining large collections of text and converting the unstructured text data into structured data for further analysis like visualization and model building.

Word Embedding

BERT

Pre-processing

Sentiment Analysis

Topic Models

1. LDA/Gibbs 

2. Structural

3. Non-negative factorization

Hidden Markov Chain

## Deep Learning

Single layer and multi-layer perceptron neural nets

Convolutional Neural Network

Recursive Neural Network

Self-organizing maps

Dropout

Batch Normalization

Back propagation

Keras

Tensorflow

## Recommendation Systems

## Information Retrieval

Search/Display

Ads retrieval and recommendation

Spam-traffic and click-farm detection

Infrastructure development

Traffic and revenue prediction

Ads pricing

Audience expansion

## Links to online resources

[An Introduction to Statistical Learning](https://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)

[The Elements of Statistical Learning (2nd edition)](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf)

[CS231n Convolutional Neural Networks for Visual Recognition](http://cs231n.github.io/)
